Now that you have the intuition behind
the use of cosine of the angle between two vectors representations as a similarity
metric, I'll go deeper into an explanation and then show you how to calculate
the cosine similarity metric. In this section, you will get the cosine
of the inner angle of two vectors. Then I'll show you how the value
of the cosine similarity is related to the similarity of
the directions of two vectors. First, you have to recall some
definitions from algebra. The norm of a vector or
its magnitude is written like this. It's defined to be the square root
of the sum of its elements squared. The dot product between
two vectors is the sum of the products between their elements
in each dimension of the vector space. Let's take another look at two of
the corpora from the last section. Remember that in this example, you have
a vector space where the representation of the corpora is given by the number of
occurrences of the words disease and eggs. The angle between those vector
representations is denoted by beta. The agriculture corpus is
represented by the vector v, and the history corpus is
going to be vector w. The dot products between those
vectors is defined as follows. From this equation, you see that
the cosine of the angle beta is equal to the dot product between the vectors
divided by the product of the two norms. Replacing the actual values
from the vector representations should give you this expression. In the numerator, you have the product
between the occurrences of the words, disease and eggs. And in the denominator, you have
the product between the norm of the vector representations of the agriculture and
history corpora. Ultimately, you should get
a cosine similarity of 0.87. Feel free to pause and
do the calculations yourself. But what does this metric tell you about
the similarity of two different vectors? Consider when two vectors are orthogonal
in the vector spaces that you know so far. It is only possible to have
positive values for any dimension. So the maximum angle between
pair of vectors is 90 degrees. In that case, the cosine would be equal
to zero, and it would mean that the two vectors have orthogonal directions or
that they are maximally the similar. Now, let's look at the case where
the vectors have the same direction. In this case,
the angle between them is zero degrees and the cosine is equal to one,
because cosine of zero is just one. As you can see, as the cosine of the angle
between two vectors approaches one, the closer their directions are. Now, you know how to get the cosine
similarity between any pair of vectors. An important takeaway is that,
this metric is proportional to the similarity between the directions
of the vectors that you are comparing. And that for
the vector spaces you've seen so far, the cosine similarity
takes values between 0 and 1. You just computed that the cosine
similarity score between two vectors. In the next video, you will learn
how to manipulate these two vectors. See you in the next video.